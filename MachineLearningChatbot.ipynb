{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the Data\n"
      ],
      "metadata": {
        "id": "Lx2bFaZ4CwBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open(\"data.json\") as json_data:\n",
        "  data = json.load(json_data)"
      ],
      "metadata": {
        "id": "_7e4pfVACy-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VETI127DvMn",
        "outputId": "e6b777a9-2574-4bc1-f92d-ce0a85bd69a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'intents': [{'tag': 'greeting', 'patterns': ['Hello', 'Hi', 'I need help', 'Hey'], 'responses': ['Hi there! How can I help?', 'Hello, and welcome to this chatbot'], 'context_set': ''}, {'tag': 'bye', 'patterns': ['Thank you for the help', 'Bye', 'Great thanks'], 'responses': ['Do you have any further questions?', 'Thanks for asking a question']}, {'tag': 'courses', 'patterns': ['What are the courses available?', 'Do you have courses?'], 'responses': ['We have courses on creative design, programming and machine learning', 'We have over 300 courses available']}, {'tag': 'coding', 'patterns': ['What coding courses do you have?', 'I want to learn programming'], 'responses': ['We have many courses, including Hello Coding and Python for Automation', 'Check out our site listing for a complete list of courses']}, {'tag': 'machinelearning', 'patterns': ['What machine learning courses do you teach?', 'Do you teach AI?', 'I want to learn artificial intelligence'], 'responses': ['We have Complete Machine Learning, ChatGPT Bundle and much more', 'Find top machine learning courses in our site catalogue']}, {'tag': 'creative', 'patterns': ['Do you teach creative courses', 'Do you have non coding courses', ' I want to learn something else'], 'responses': ['We have tons of non coding courses', 'Check our site for more courses', ' We teach video editing, audio production, graphic design and much more!']}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "1OO8uqejFap9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gT0ygs4AGpW7",
        "outputId": "c9342336-4c4a-4a78-9bcf-5be1649cda3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = []\n",
        "documents = []\n",
        "classes = []\n",
        "\n",
        "for intent in data[\"intents\"]:\n",
        "  for pattern in intent[\"patterns\"]:\n",
        "    word = nltk.word_tokenize(pattern)\n",
        "\n",
        "    words.extend(word)\n",
        "    documents.append((word, intent[\"tag\"]))\n",
        "\n",
        "    if intent[\"tag\"] not in classes:\n",
        "      classes.append(intent[\"tag\"])"
      ],
      "metadata": {
        "id": "8K1uC5XxFQLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7jCoRyPG4r_",
        "outputId": "3c1085b8-6122-4a0d-e7be-b39820bc45e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', 'Hi', 'I', 'need', 'help', 'Hey', 'Thank', 'you', 'for', 'the', 'help', 'Bye', 'Great', 'thanks', 'What', 'are', 'the', 'courses', 'available', '?', 'Do', 'you', 'have', 'courses', '?', 'What', 'coding', 'courses', 'do', 'you', 'have', '?', 'I', 'want', 'to', 'learn', 'programming', 'What', 'machine', 'learning', 'courses', 'do', 'you', 'teach', '?', 'Do', 'you', 'teach', 'AI', '?', 'I', 'want', 'to', 'learn', 'artificial', 'intelligence', 'Do', 'you', 'teach', 'creative', 'courses', 'Do', 'you', 'have', 'non', 'coding', 'courses', 'I', 'want', 'to', 'learn', 'something', 'else']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyYF5qTXHCGv",
        "outputId": "c3612755-b352-444f-f289-cb03c06d76a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(['Hello'], 'greeting'), (['Hi'], 'greeting'), (['I', 'need', 'help'], 'greeting'), (['Hey'], 'greeting'), (['Thank', 'you', 'for', 'the', 'help'], 'bye'), (['Bye'], 'bye'), (['Great', 'thanks'], 'bye'), (['What', 'are', 'the', 'courses', 'available', '?'], 'courses'), (['Do', 'you', 'have', 'courses', '?'], 'courses'), (['What', 'coding', 'courses', 'do', 'you', 'have', '?'], 'coding'), (['I', 'want', 'to', 'learn', 'programming'], 'coding'), (['What', 'machine', 'learning', 'courses', 'do', 'you', 'teach', '?'], 'machinelearning'), (['Do', 'you', 'teach', 'AI', '?'], 'machinelearning'), (['I', 'want', 'to', 'learn', 'artificial', 'intelligence'], 'machinelearning'), (['Do', 'you', 'teach', 'creative', 'courses'], 'creative'), (['Do', 'you', 'have', 'non', 'coding', 'courses'], 'creative'), (['I', 'want', 'to', 'learn', 'something', 'else'], 'creative')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRq66aMXHFIu",
        "outputId": "5c3b7569-744b-4d60-c9df-9026c813ba4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['greeting', 'bye', 'courses', 'coding', 'machinelearning', 'creative']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleaning Chat Data for Machine Learning\n"
      ],
      "metadata": {
        "id": "LU5O6oe-HUH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "stemmer = LancasterStemmer()\n",
        "\n",
        "words = [stemmer.stem(word.lower()) for word in words]\n",
        "\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQLV6sozHaO_",
        "outputId": "f928cf93-bbc7-4cb3-a097-16419fa335c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello', 'hi', 'i', 'nee', 'help', 'hey', 'thank', 'you', 'for', 'the', 'help', 'bye', 'gre', 'thank', 'what', 'ar', 'the', 'cours', 'avail', '?', 'do', 'you', 'hav', 'cours', '?', 'what', 'cod', 'cours', 'do', 'you', 'hav', '?', 'i', 'want', 'to', 'learn', 'program', 'what', 'machin', 'learn', 'cours', 'do', 'you', 'teach', '?', 'do', 'you', 'teach', 'ai', '?', 'i', 'want', 'to', 'learn', 'art', 'intellig', 'do', 'you', 'teach', 'cre', 'cours', 'do', 'you', 'hav', 'non', 'cod', 'cours', 'i', 'want', 'to', 'learn', 'someth', 'els']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = sorted(list(set(words)))\n",
        "#sorts words into alphabetical order\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XblPB9R-IGGK",
        "outputId": "d4b15c6f-0f10-492a-f038-21014e331344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['?', 'ai', 'ar', 'art', 'avail', 'bye', 'cod', 'cours', 'cre', 'do', 'els', 'for', 'gre', 'hav', 'hello', 'help', 'hey', 'hi', 'i', 'intellig', 'learn', 'machin', 'nee', 'non', 'program', 'someth', 'teach', 'thank', 'the', 'to', 'want', 'what', 'you']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building words"
      ],
      "metadata": {
        "id": "5hTqUdYeJD_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7acOOckWJOO9",
        "outputId": "85bd8b2a-06bb-4cc7-f2bd-3d9425f9af27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(['Hello'], 'greeting'), (['Hi'], 'greeting'), (['I', 'need', 'help'], 'greeting'), (['Hey'], 'greeting'), (['Thank', 'you', 'for', 'the', 'help'], 'bye'), (['Bye'], 'bye'), (['Great', 'thanks'], 'bye'), (['What', 'are', 'the', 'courses', 'available', '?'], 'courses'), (['Do', 'you', 'have', 'courses', '?'], 'courses'), (['What', 'coding', 'courses', 'do', 'you', 'have', '?'], 'coding'), (['I', 'want', 'to', 'learn', 'programming'], 'coding'), (['What', 'machine', 'learning', 'courses', 'do', 'you', 'teach', '?'], 'machinelearning'), (['Do', 'you', 'teach', 'AI', '?'], 'machinelearning'), (['I', 'want', 'to', 'learn', 'artificial', 'intelligence'], 'machinelearning'), (['Do', 'you', 'teach', 'creative', 'courses'], 'creative'), (['Do', 'you', 'have', 'non', 'coding', 'courses'], 'creative'), (['I', 'want', 'to', 'learn', 'something', 'else'], 'creative')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "empty_output = [0] * len(classes)\n",
        "\n",
        "print(empty_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GyaJQT4na-T",
        "outputId": "d50170d1-cefd-4695-92d2-c2cf4eb7ee66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = []\n",
        "\n",
        "for document in documents:\n",
        "  bag_of_words = []\n",
        "\n",
        "  pattern_words = document[0]\n",
        "  pattern_words = [stemmer.stem(word.lower()) for word in pattern_words]\n",
        "\n",
        "  for word in words:\n",
        "    bag_of_words.append(1) if word in pattern_words else bag_of_words.append(0)\n",
        "\n",
        "  output_row = list(empty_output)\n",
        "  output_row[classes.index(document[1])] = 1\n",
        "  training_data.append([bag_of_words, output_row])"
      ],
      "metadata": {
        "id": "il5PmYUOJXtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pattern_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSQPOttoKcSq",
        "outputId": "0a82f595-f94a-420d-d727-141d8ae010dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'want', 'to', 'learn', 'someth', 'els']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNq8VN0YomiB",
        "outputId": "c92a8cae-89ed-4a86-8964-699e825edd3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1], [0, 1, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0]], [[1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0], [0, 0, 1, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 1, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], [0, 0, 0, 1, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0], [0, 0, 0, 1, 0, 0]], [[1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1], [0, 0, 0, 0, 1, 0]], [[1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 1, 0]], [[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0], [0, 0, 0, 0, 1, 0]], [[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 1]], [[0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 1]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0], [0, 0, 0, 0, 0, 1]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split data for machine learning"
      ],
      "metadata": {
        "id": "IGepkIvEouz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random.shuffle(training_data)\n",
        "\n",
        "print(training_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkQLgRx5o477",
        "outputId": "56968091-c3c6-4276-ba85-4b2f4174a3ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], [0, 0, 0, 1, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 1]], [[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 1]], [[1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1], [0, 0, 0, 0, 1, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 1, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1], [0, 1, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0], [0, 0, 0, 0, 0, 1]], [[1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0], [0, 0, 1, 0, 0, 0]], [[1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 1, 0]], [[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0], [0, 0, 0, 0, 1, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0], [0, 0, 0, 1, 0, 0]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(training_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m18VAFc4pKPB",
        "outputId": "7b552a70-27da-44fb-f030-3ee8d21d2175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "\n",
        "training_numpy = numpy.array(training_data)\n",
        "\n",
        "print(training_numpy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhfzdiqSpWGT",
        "outputId": "667a7db3-dafa-4f2b-aebe-48f6dddaf5b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[list([1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1])\n",
            "  list([0, 0, 0, 1, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1])\n",
            "  list([0, 0, 0, 0, 0, 1])]\n",
            " [list([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "  list([0, 1, 0, 0, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "  list([1, 0, 0, 0, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
            "  list([0, 0, 0, 0, 0, 1])]\n",
            " [list([1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1])\n",
            "  list([0, 0, 0, 0, 1, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "  list([1, 0, 0, 0, 0, 0])]\n",
            " [list([1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
            "  list([0, 0, 1, 0, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "  list([1, 0, 0, 0, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1])\n",
            "  list([0, 1, 0, 0, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "  list([1, 0, 0, 0, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0])\n",
            "  list([0, 1, 0, 0, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0])\n",
            "  list([0, 0, 0, 0, 0, 1])]\n",
            " [list([1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0])\n",
            "  list([0, 0, 1, 0, 0, 0])]\n",
            " [list([1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1])\n",
            "  list([0, 0, 0, 0, 1, 0])]\n",
            " [list([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0])\n",
            "  list([0, 0, 0, 0, 1, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0])\n",
            "  list([0, 0, 0, 1, 0, 0])]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-060941f16bee>:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  training_numpy = numpy.array(training_data)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(training_numpy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nWPR-c_pvWU",
        "outputId": "dc0ee3bd-6752-415a-c0ca-fd639d86c2b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = list(training_numpy[:,0])\n",
        "\n",
        "print(train_X)"
      ],
      "metadata": {
        "id": "QPLhx2W7p9HL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d01afde7-8a18-49d3-e7b4-6bb4245cf439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0], [1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0], [1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5YZ8S-Aiu7R",
        "outputId": "0b84805b-48a8-4123-cea3-bc9025062be5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = list(training_numpy[:,1])\n",
        "\n",
        "print(train_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kY1UVRWizW_",
        "outputId": "93019f8f-dc14-4e3b-bea6-6fc8b99107e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 1], [0, 1, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 1, 0], [1, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0], [1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1], [0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 1, 0], [0, 0, 0, 1, 0, 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a TensorFlow machine learning model for chatbot"
      ],
      "metadata": {
        "id": "Alrb7T-LjN5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tflearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6QslS6_jWS2",
        "outputId": "18c06887-a8ec-4247-8d5d-28289f72565c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tflearn\n",
            "  Downloading tflearn-0.5.0.tar.gz (107 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/107.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.3/107.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tflearn) (1.22.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tflearn) (1.16.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from tflearn) (9.4.0)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tflearn: filename=tflearn-0.5.0-py3-none-any.whl size=127282 sha256=189b9a2b50072bba3919c26ab501587d4f933c1c05110658af80e2c2125840d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/55/fb/7b/e06204a0ceefa45443930b9a250cb5ebe31def0e4e8245a465\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tflearn\n",
        "\n",
        "neural_network = tflearn.input_data(shape = [None, len(train_X[0])])\n",
        "\n",
        "print(neural_network)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-A2-5TvJj7ot",
        "outputId": "4e310a96-85b8-4df4-8b30-10927ab4b7a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"InputData/X:0\", shape=(?, 33), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neural_network = tflearn.fully_connected(neural_network, 8)\n",
        "\n",
        "print(neural_network)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_X0JL_tkQvF",
        "outputId": "daab3338-43e6-4e7e-dbae-6eaa337b0466"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tflearn/initializations.py:164: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"FullyConnected/BiasAdd:0\", shape=(?, 8), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neural_network = tflearn.fully_connected(neural_network, len(train_y[0]), activation=\"softmax\")\n",
        "\n",
        "print(neural_network)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rfY6HEEkkm_",
        "outputId": "3c5ae554-4731-4361-e7a5-e991e5bbf98f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"FullyConnected_1/Softmax:0\", shape=(?, 6), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neural_network = tflearn.regression(neural_network)\n",
        "\n",
        "print(neural_network)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3u3O2bakzmo",
        "outputId": "32643eb8-d69d-474d-be70-7381b7dbf817"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"FullyConnected_1/Softmax:0\", shape=(?, 6), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tflearn.DNN(neural_network)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHYHy38EmD3W",
        "outputId": "232e38a3-f924-4d2b-e602-e17a746b8214"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tflearn.models.dnn.DNN object at 0x78dede3590c0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_X, train_y, n_epoch= 2000, batch_size= 8, show_metric= True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAZTe3TymL9j",
        "outputId": "bea854e6-6ff8-43d3-ee8e-094000781902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Step: 11999  | total loss: \u001b[1m\u001b[32m0.00022\u001b[0m\u001b[0m | time: 0.008s\n",
            "| Adam | epoch: 4000 | loss: 0.00022 - acc: 1.0000 -- iter: 16/17\n",
            "Training Step: 12000  | total loss: \u001b[1m\u001b[32m0.00029\u001b[0m\u001b[0m | time: 0.012s\n",
            "| Adam | epoch: 4000 | loss: 0.00029 - acc: 1.0000 -- iter: 17/17\n",
            "--\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Chatbot machine learning model"
      ],
      "metadata": {
        "id": "ODXrzT4mnMl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"chatbot_dnn.tflearn\")"
      ],
      "metadata": {
        "id": "79kcygndnYvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load(\"chatbot_dnn.tflearn\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEdPYzdwn5c_",
        "outputId": "86cc21b5-0be6-4531-826a-c34587cf55c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEYQM1wIoJ7c",
        "outputId": "c03acd7f-de8a-4990-ef17-c37a664cc2f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tflearn.models.dnn.DNN object at 0x78dede3590c0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Do you sell any coding course?\""
      ],
      "metadata": {
        "id": "5bkOwH0cobTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_question(question):\n",
        "  question_tokenized = nltk.word_tokenize(question)\n",
        "\n",
        "  question_stemmed = [stemmer.stem(word.lower()) for word in question_tokenized]\n",
        "\n",
        "  bag = [0] * len(words)\n",
        "\n",
        "  for stem in question_stemmed:\n",
        "    for index,  word in enumerate(words):\n",
        "      if word == stem:\n",
        "        bag[index] = 1\n",
        "\n",
        "  return(numpy.array(bag))"
      ],
      "metadata": {
        "id": "7X7tllxaoqfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_question(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fo3BBbto9g6",
        "outputId": "f7efc08c-26f7-4514-f07a-3bb9090e4e93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict([process_question(question)])"
      ],
      "metadata": {
        "id": "gNaVHiVSoRSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4gqB3fUqR_6",
        "outputId": "cdd4e428-ae5d-4a22-d25c-6a88cf3f379c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.7082592e-04 3.3792356e-04 8.8555321e-02 7.7985632e-01 8.9004049e-03\n",
            " 1.2217923e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tqbNJlNqsmL",
        "outputId": "441fb523-2d24-4220-a25e-439e8abf28e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['greeting', 'bye', 'courses', 'coding', 'machinelearning', 'creative']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Categorize chat question with ML"
      ],
      "metadata": {
        "id": "ZcO6__n1q6un"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def categorize(prediction):\n",
        "\n",
        "  prediction_top = [[index, result] for index, result in enumerate(prediction) if result > 0.5]\n",
        "\n",
        "  prediction_top.sort(key = lambda x: x[1], reverse = True)\n",
        "\n",
        "  result = []\n",
        "\n",
        "  for prediction_value in prediction_top:\n",
        "    result.append((classes[prediction_value[0]], prediction_value[1]))\n",
        "\n",
        "  return result\n",
        "\n"
      ],
      "metadata": {
        "id": "lUQVxG0ArAas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorize(prediction[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExEXt_XZr6Lu",
        "outputId": "e9d7a635-4a6f-4f9b-b6ab-20f5e6ab7c7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('coding', 0.7798563)]"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot(question):\n",
        "  prediction = model.predict([process_question(question)])\n",
        "\n",
        "  result = categorize(prediction[0])\n",
        "\n",
        "  return(result)"
      ],
      "metadata": {
        "id": "KwDpCIkSEmXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pick a chatbot response in top category"
      ],
      "metadata": {
        "id": "Z4aJeMJiF6kz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = input(\"Do you have a question for me?\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6RRMqa0F_Rp",
        "outputId": "8e649903-8b80-4235-eb60-eadb2216f548"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Do you have a question for me?\n",
            "Hello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(user_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTa0FMW_GUPf",
        "outputId": "886cbdfc-2e7f-4497-ac0c-d02889051f1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def respond_to_input(user_input):\n",
        "\n",
        "  question_category = chatbot(user_input)\n",
        "\n",
        "  if question_category:\n",
        "    while question_category:\n",
        "      for intent in data[\"intents\"]:\n",
        "        if intent[\"tag\"] == question_category[0][0]:\n",
        "          return random.choice(intent[\"responses\"])"
      ],
      "metadata": {
        "id": "Ph45xDaKGXpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "respond_to_input(user_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "itjetqLAGt_-",
        "outputId": "6473709f-c1fa-4502-fd5c-f5dbee9d21c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello, and welcome to this chatbot'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  user_input = input(\"Do you have a question for me?\\n\")\n",
        "  response = respond_to_input(user_input)\n",
        "  print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "9Mmeqw6XHnd8",
        "outputId": "799537d6-4ed0-4a10-c1e0-d5c9316f9f2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Do you have a question for me?\n",
            "What products do you sell\n",
            "We have many courses, including Hello Coding and Python for Automation\n",
            "Do you have a question for me?\n",
            "Hi\n",
            "Hello, and welcome to this chatbot\n",
            "Do you have a question for me?\n",
            "hi\n",
            "Hello, and welcome to this chatbot\n",
            "Do you have a question for me?\n",
            "hello\n",
            "Hello, and welcome to this chatbot\n",
            "Do you have a question for me?\n",
            "what products do you sell\n",
            "Check out our site listing for a complete list of courses\n",
            "Do you have a question for me?\n",
            "what courses do you have?\n",
            "We have courses on creative design, programming and machine learning\n",
            "Do you have a question for me?\n",
            "I like machine learning\n",
            "We have Complete Machine Learning, ChatGPT Bundle and much more\n",
            "Do you have a question for me?\n",
            "what colors do you like\n",
            "Check out our site listing for a complete list of courses\n",
            "Do you have a question for me?\n",
            "good bye\n",
            "Thanks for asking a question\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-137-b33f4c3f2e8b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Do you have a question for me?\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrespond_to_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}